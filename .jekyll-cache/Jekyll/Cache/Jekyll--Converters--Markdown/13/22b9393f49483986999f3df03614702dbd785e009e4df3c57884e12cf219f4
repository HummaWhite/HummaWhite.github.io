I"D<h2 id="zillum-renderer">Zillum Renderer</h2>
<p><a href="https://github.com/HummaWhite/Zillum">Zillum</a> is my ray tracer, under development since I seriously began to study realistic image synthesis in Sep 2020. Now it has two versions, one running on CPU, another on GPU by OpenGL compute shader, which is also named <a href="https://github.com/HummaWhite/ZillumGL">ZillumGL</a>.
I’ve made videos about the GPU version, you can view them through the links: <a href="https://youtu.be/pjfcD8fYfQg">Low-discrepancy sampler test</a>, <a href="https://youtu.be/TGbwSyqxKvY">Rendering the Gallery scene</a></p>

<p>Typically when I want to verify new light transport methods I learn, I’ll first code them in the CPU version, then I would consider how to implement those on GPU and optimize.</p>

<hr />
<h2 id="software-rasterizer">Software Rasterizer</h2>
<p>In the month before I started to learned offline rendering, I tried to implement a <a href="https://github.com/HummaWhite/SoftRaster">software rasterizer</a> which emulates the functions of modern hardware graphics pipelines.</p>
:ET